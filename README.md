![Python](https://img.shields.io/badge/Python-3670A0?style=flat&logo=python&logoColor=ffdd54)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white)
![Scrapy](https://img.shields.io/badge/Scrapy-60A839?style=flat&logo=scrapy&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=flat&logo=plotly&logoColor=white)
![Statistics](https://img.shields.io/badge/Statistics-Correlation%20|%20Permutation%20Testing%20|%20Granger%20Causality-blue)

## OSINT Researcher | Investigative Data Support

**19D Veteran** building statistically validated research frameworks for temporal pattern analysis, capital flow tracking, and institutional accountability.

---

### ðŸ“Œ Featured: [The Regulated Friction Project](https://github.com/Leerrooy95/The_Regulated_Friction_Project)

Documents statistically significant correlations between high-visibility events and institutional positioning â€” with a live dashboard, automated extraction pipeline, and 25 falsifiable predictions (4 publicly failed, 11 confirmed).

**[ðŸ“Š Live Dashboard â†’](https://regulatedfriction.streamlit.app)**

| Finding | Value |
|---------|-------|
| Core correlation | r = +0.6196 (p = 0.0004) |
| Historical backfill | 66 verified pairs (2017â€“2024) |
| Response rate | 93% of friction events â†’ compliance within 14 days |
| Robustness | Permutation (p < 0.001), Granger causality (p = 0.0008), block bootstrap (p = 0.008) |
| Live extraction | Llama-4-Scout pipeline with convergence node tracking |

---

### ðŸ“ˆ How I Got Here

Started with **[UVB-76](https://github.com/Leerrooy95/UVB-76-Structured-Signal-Analysis)** â€” gathering data by hand, learning pattern recognition from raw signals.

Middle repos taught me the hard way about AI hallucinations. Those repos are corrected and kept public as lessons in data verification.

Picked up from there by downloading scattered **[Arkansas Department of Corrections](https://github.com/Leerrooy95/Arkansas-DOC-Expenditures-2015-2025)** PDFs, OCR'ing them into clean datasets, and analyzing spending patterns that hadn't been aggregated before.

**[The Regulated Friction Project](https://github.com/Leerrooy95/The_Regulated_Friction_Project)** is where methodology caught up with ambition â€” automated scraping, statistical validation, reproducible findings, and a live intelligence dashboard fed by LLM extraction.

---

### ðŸ”§ What I Build

- **Temporal correlation frameworks** â€” lag analysis, permutation testing, convergence modeling
- **OSINT pipelines** â€” Federal Register scrapers, 13F tracking, EO spiders
- **Live dashboards** â€” Streamlit + Plotly with automated LLM extraction feeds
- **Reproducible research** â€” every finding ships with the scripts to verify it

---

### ðŸ¤ Open To

- Investigative data support and OSINT collaboration
- Temporal pattern analysis and capital flow tracking
- Newsroom data partnerships

**Contact:** Discord and email in profile description

---

*Last updated: February 22, 2026*
